# -*- coding: utf-8 -*-
"""Load and Spotpris Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Tks7CVIO0VXHKG0b7TFnsvsMo8EDnISf
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
import matplotlib.pyplot as plt

# Load your hourly site load data
df = pd.read_csv('/content/hourly_site_load_data_rounded.csv', index_col='datetime', parse_dates=True)

# Create features for day, hour, etc., that may help in the prediction
df['day_of_week'] = df.index.dayofweek
df['hour'] = df.index.hour

# Prepare the data for training the model
X = df[['day_of_week', 'hour']]  # Features
y = df['load in w']  # Target variable (load in watts)

# Split the data into training and test sets (80% training, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the Random Forest Regressor
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Predict on the test set to check performance
y_pred = rf.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
print(f'Mean Absolute Error on test set: {mae}')

# Plot the real vs predicted values for the test set
plt.figure(figsize=(10, 6))
plt.plot(y_test.values[:100], label='Real Load', color='blue', linestyle='dashed')  # First 100 points for simplicity
plt.plot(y_pred[:100], label='Predicted Load', color='orange')
plt.title('Real vs Predicted Load')
plt.xlabel('Sample')
plt.ylabel('Load in W')
plt.legend()
plt.show()

# Generate future timestamps for the next 7 days (7 * 24 hours)
future_dates = pd.date_range(start=df.index[-1], periods=7*24+1, freq='H')[1:]

# Create a DataFrame for the future features (day of week, hour)
future_features = pd.DataFrame({
    'day_of_week': future_dates.dayofweek,
    'hour': future_dates.hour
}, index=future_dates)

# Predict the future load values
future_load_pred = rf.predict(future_features)

# Create a DataFrame for the forecasted values
forecast_df = pd.DataFrame(future_load_pred, index=future_dates, columns=['forecasted_load'])

# Plot the forecasted values along with the past week of actual data
plt.figure(figsize=(10, 6))
plt.plot(df.index[-24*7:], df['load in w'][-24*7:], label='Past Load', color='blue')  # Last week of actual data
plt.plot(future_dates, forecast_df['forecasted_load'], label='Forecasted Load', color='orange')
plt.title('Load Forecast for the Next 7 Days')
plt.xlabel('Date')
plt.ylabel('Load in W')
plt.legend()
plt.show()

# Round the forecasted values to 2 decimal places
forecast_df_rounded = forecast_df.round(2)

# Save the rounded forecast data to CSV
forecast_df_rounded.to_csv('load_forecast_next_7_days.csv')



# Create features for day, hour, etc., that may help in the prediction
df['day_of_week'] = df.index.dayofweek
df['hour'] = df.index.hour

# Prepare the data for training the model
X = df[['day_of_week', 'hour']]  # Features
y = df['load in w']  # Target variable (load in watts)

# Split the data into training and test sets (80% training, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the Random Forest Regressor with hyperparameter tuning to prevent overfitting
rf = RandomForestRegressor(
    n_estimators=100,         # Number of trees
    max_depth=10,             # Limit tree depth
    min_samples_split=10,     # Minimum number of samples to split a node
    min_samples_leaf=4,       # Minimum samples required at leaf node
    max_features='sqrt',      # Number of features to consider at each split
    bootstrap=True,           # Use bootstrap sampling
    random_state=42           # For reproducibility
)

# Train the model
rf.fit(X_train, y_train)

# Predict on the test set to check performance
y_pred = rf.predict(X_test)
mae = mean_absolute_error(y_test, y_pred)
print(f'Mean Absolute Error on test set: {mae}')

# Plot the real vs predicted values for the test set
plt.figure(figsize=(10, 6))
plt.plot(y_test.values[:100], label='Real Load', color='blue', linestyle='dashed')  # First 100 points for simplicity
plt.plot(y_pred[:100], label='Predicted Load', color='orange')
plt.title('Real vs Predicted Load')
plt.xlabel('Sample')
plt.ylabel('Load in W')
plt.legend()
plt.show()

# Generate future timestamps for the next 7 days (7 * 24 hours)
future_dates = pd.date_range(start=df.index[-1], periods=7*24+1, freq='H')[1:]

# Create a DataFrame for the future features (day of week, hour)
future_features = pd.DataFrame({
    'day_of_week': future_dates.dayofweek,
    'hour': future_dates.hour
}, index=future_dates)

# Predict the future load values
future_load_pred = rf.predict(future_features)

# Create a DataFrame for the forecasted values
forecast_df = pd.DataFrame(future_load_pred, index=future_dates, columns=['forecasted_load'])

# Round the forecasted values to 2 decimal places
forecast_df_rounded = forecast_df.round(2)

# Plot the forecasted values along with the past week of actual data
plt.figure(figsize=(10, 6))
plt.plot(df.index[-24*7:], df['load in w'][-24*7:], label='Past Load', color='blue')  # Last week of actual data
plt.plot(future_dates, forecast_df_rounded['forecasted_load'], label='Forecasted Load', color='orange')
plt.title('Load Forecast for the Next 7 Days')
plt.xlabel('Date')
plt.ylabel('Load in W')
plt.legend()
plt.show()

# Save the rounded forecast data to CSV
forecast_df_rounded.to_csv('test_load_forecast_next_7_days.csv')
